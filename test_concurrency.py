#!/usr/bin/env python3
"""
å¹¶å‘æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•3D-SpeakeræœåŠ¡çš„å¹¶å‘å¤„ç†èƒ½åŠ›
"""

import asyncio
import aiohttp
import time
import statistics
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
import json

class PerformanceTester:
    def __init__(self, base_url="http://localhost:7001"):
        self.base_url = base_url
        self.health_url = f"{base_url}/health"

    def test_health_endpoint(self, concurrent_users=10, total_requests=100):
        """æµ‹è¯•healthç«¯ç‚¹çš„å¹¶å‘æ€§èƒ½"""
        print(f"\n=== Healthç«¯ç‚¹å¹¶å‘æµ‹è¯• ===")
        print(f"å¹¶å‘ç”¨æˆ·: {concurrent_users}")
        print(f"æ€»è¯·æ±‚æ•°: {total_requests}")

        start_time = time.time()
        response_times = []
        success_count = 0
        error_count = 0

        def make_request():
            try:
                start = time.time()
                response = requests.get(self.health_url, timeout=30)
                end = time.time()

                response_time = end - start
                response_times.append(response_time)

                if response.status_code == 200:
                    return True, response_time, response.status_code
                else:
                    return False, response_time, response.status_code
            except Exception as e:
                return False, 0, str(e)

        with ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [executor.submit(make_request) for _ in range(total_requests)]

            for future in as_completed(futures):
                success, response_time, status = future.result()
                if success:
                    success_count += 1
                else:
                    error_count += 1

        total_time = time.time() - start_time

        # è®¡ç®—ç»Ÿè®¡æ•°æ®
        if response_times:
            avg_response_time = statistics.mean(response_times)
            median_response_time = statistics.median(response_times)
            p95_response_time = sorted(response_times)[int(len(response_times) * 0.95)]
            p99_response_time = sorted(response_times)[int(len(response_times) * 0.99)]
            min_response_time = min(response_times)
            max_response_time = max(response_times)
        else:
            avg_response_time = median_response_time = p95_response_time = p99_response_time = 0
            min_response_time = max_response_time = 0

        rps = total_requests / total_time
        success_rate = (success_count / total_requests) * 100

        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"æˆåŠŸè¯·æ±‚: {success_count}/{total_requests}")
        print(f"å¤±è´¥è¯·æ±‚: {error_count}")
        print(f"æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"QPS (æ¯ç§’è¯·æ±‚æ•°): {rps:.1f}")
        print(f"\nâ±ï¸ å“åº”æ—¶é—´ç»Ÿè®¡:")
        print(f"å¹³å‡å“åº”æ—¶é—´: {avg_response_time*1000:.1f}ms")
        print(f"ä¸­ä½æ•°å“åº”æ—¶é—´: {median_response_time*1000:.1f}ms")
        print(f"95%å“åº”æ—¶é—´: {p95_response_time*1000:.1f}ms")
        print(f"99%å“åº”æ—¶é—´: {p99_response_time*1000:.1f}ms")
        print(f"æœ€å°å“åº”æ—¶é—´: {min_response_time*1000:.1f}ms")
        print(f"æœ€å¤§å“åº”æ—¶é—´: {max_response_time*1000:.1f}ms")

        return {
            'success_rate': success_rate,
            'qps': rps,
            'avg_response_time': avg_response_time,
            'p95_response_time': p95_response_time,
            'total_time': total_time
        }

    def test_concurrent_loads(self):
        """æµ‹è¯•ä¸åŒå¹¶å‘è´Ÿè½½ä¸‹çš„æ€§èƒ½"""
        print("\nğŸ”¥ å¤šçº§å¹¶å‘è´Ÿè½½æµ‹è¯•")
        print("=" * 50)

        test_scenarios = [
            (5, 50),     # 5å¹¶å‘ç”¨æˆ·ï¼Œ50ä¸ªè¯·æ±‚
            (10, 100),   # 10å¹¶å‘ç”¨æˆ·ï¼Œ100ä¸ªè¯·æ±‚
            (20, 200),   # 20å¹¶å‘ç”¨æˆ·ï¼Œ200ä¸ªè¯·æ±‚
            (50, 500),   # 50å¹¶å‘ç”¨æˆ·ï¼Œ500ä¸ªè¯·æ±‚
            (100, 1000), # 100å¹¶å‘ç”¨æˆ·ï¼Œ1000ä¸ªè¯·æ±‚
        ]

        results = []

        for concurrent_users, total_requests in test_scenarios:
            print(f"\nğŸ§ª æµ‹è¯•åœºæ™¯: {concurrent_users}å¹¶å‘ç”¨æˆ· x {total_requests}è¯·æ±‚")
            result = self.test_health_endpoint(concurrent_users, total_requests)
            result['concurrent_users'] = concurrent_users
            result['total_requests'] = total_requests
            results.append(result)

            # ç­‰å¾…æœåŠ¡å™¨æ¢å¤
            print("â³ ç­‰å¾…3ç§’...")
            time.sleep(3)

            # å¦‚æœæˆåŠŸç‡å¤ªä½ï¼Œåœæ­¢æµ‹è¯•
            if result['success_rate'] < 90:
                print(f"âš ï¸ æˆåŠŸç‡ä½äº90%ï¼Œåœæ­¢æµ‹è¯•")
                break

        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.generate_summary_report(results)

        return results

    def generate_summary_report(self, results):
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æ€»ç»“æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ æ€§èƒ½æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        print("="*60)

        print(f"{'å¹¶å‘æ•°':<8} {'QPS':<8} {'æˆåŠŸç‡':<8} {'å¹³å‡å“åº”':<12} {'P95å“åº”':<12}")
        print("-" * 60)

        for result in results:
            print(f"{result['concurrent_users']:<8} "
                  f"{result['qps']:<8.1f} "
                  f"{result['success_rate']:<8.1f}% "
                  f"{result['avg_response_time']*1000:<12.1f}ms "
                  f"{result['p95_response_time']*1000:<12.1f}ms")

        # æ‰¾åˆ°æœ€ä½³æ€§èƒ½ç‚¹
        if results:
            max_qps_result = max(results, key=lambda x: x['qps'])
            print(f"\nğŸ† æœ€é«˜QPS: {max_qps_result['qps']:.1f} (å¹¶å‘æ•°: {max_qps_result['concurrent_users']})")

            # æ¨èé…ç½®
            good_results = [r for r in results if r['success_rate'] >= 95 and r['p95_response_time'] < 2.0]
            if good_results:
                recommended = max(good_results, key=lambda x: x['qps'])
                print(f"ğŸ’¡ æ¨èé…ç½®: {recommended['concurrent_users']}å¹¶å‘ (QPS: {recommended['qps']:.1f}, æˆåŠŸç‡: {recommended['success_rate']:.1f}%)")

    def test_server_status(self):
        """æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€"""
        print("ğŸ” æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€...")
        try:
            response = requests.get(self.health_url, timeout=10)
            if response.status_code == 200:
                data = response.json()
                print(f"âœ… æœåŠ¡å™¨è¿è¡Œæ­£å¸¸")
                print(f"   æ¨¡å‹: {data.get('model_id', 'N/A')}")
                print(f"   è®¾å¤‡: {data.get('device', 'N/A')}")
                print(f"   æ¨¡å‹å·²åŠ è½½: {data.get('model_loaded', False)}")
                print(f"   è¿è¡Œæ—¶é—´: {data.get('uptime', 0):.1f}ç§’")
                return True
            else:
                print(f"âŒ æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨: {e}")
            return False

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        base_url = sys.argv[1]
    else:
        base_url = "http://localhost:7001"

    print(f"ğŸš€ 3D-Speaker å¹¶å‘æ€§èƒ½æµ‹è¯•")
    print(f"ğŸ”— ç›®æ ‡æœåŠ¡: {base_url}")

    tester = PerformanceTester(base_url)

    # æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€
    if not tester.test_server_status():
        print("âŒ æœåŠ¡å™¨æ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        return

    # æ‰§è¡Œå¹¶å‘æµ‹è¯•
    print("\nğŸ å¼€å§‹å¹¶å‘æ€§èƒ½æµ‹è¯•...")
    results = tester.test_concurrent_loads()

    print(f"\nğŸ¯ æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š å»ºè®®æ ¹æ®ç»“æœè°ƒæ•´Gunicorn workeræ•°é‡")
    print(f"ğŸ’¡ å½“å‰é…ç½®: 2ä¸ªworkers")

if __name__ == "__main__":
    main()